
# coding: utf-8

# In[1]:


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import style

style.use('ggplot')


# In[2]:


################### Reading data from csv files ####################

# Humidity and teperature data
dt = pd.read_csv('data/Jul.csv', index_col=0, header=3)
dt = dt.iloc[2:]
dt1 = pd.read_csv('data/Aug.csv', index_col=0, header=3)
dt1 = dt1.iloc[2:]
dt = dt.append(dt1)
dt1 = pd.read_csv('data/Sep.csv', index_col=0, header=3)
dt1 = dt1.iloc[2:]
dt = dt.append(dt1)
dt1 = pd.read_csv('data/Oct.csv', index_col=0, header=3)
dt1 = dt1.iloc[2:]
dt = dt.append(dt1)
dt1 = pd.read_csv('data/Nov.csv', index_col=0, header=3)
dt1 = dt1.iloc[2:]
dt = dt.append(dt1)

# Set index as DateTime
dt.index = dt.index.str[24:]
dt.index = pd.to_datetime(dt.index, format='%d-%b-%Y %I:%M %p')

# Data of gasses
dt1 = pd.read_excel('data/T1.xlsx', sheet_name="NO2", index_col=0, header=0)
dt2 = pd.read_excel('data/T1.xlsx', sheet_name="SO2", index_col=0, header=0)
dt3 = pd.read_excel('data/T1.xlsx', sheet_name="CO", index_col=0, header=0)
dt4 = pd.read_excel('data/T1.xlsx', sheet_name="O3", index_col=0, header=0)

dt['NO2'] = dt1['Aurassure']
dt['SO2'] = dt2['Aurassure']
dt['CO'] = dt3['Aurassure']
dt['O3'] = dt4['Aurassure']

dt['Jindal'] = dt1['Jindal']

# interpolation of NaN values
dt['Jindal'].interpolate(inplace=True, limit_direction='both')
dt['NO2'].interpolate(inplace=True, limit_direction='both')
dt['SO2'].interpolate(inplace=True, limit_direction='both')
dt['CO'].interpolate(inplace=True, limit_direction='both')
dt['O3'].interpolate(inplace=True, limit_direction='both')

# Convert all values to int
dt = dt.apply(pd.to_numeric, errors='ignore')
dt


# In[8]:


################ Removal of outliers ########################

# Remove data with low frequency and away from mean

dt = dt[dt.NO2 < 100]
dt.NO2.hist()
plt.title('NO2')
plt.show()

dt.SO2.hist()
plt.title('SO2')
plt.show()

# dt = dt[dt.CO > 20]
dt = dt[dt.CO < 0.9]
dt.CO.hist()
plt.title('CO')
plt.show()

dt.O3.hist()
plt.title('O3')
plt.show()

dt = dt[dt.Jindal < 13] #NO2
dt.Jindal.hist()
plt.title('Jindal')
plt.show()

dt = dt[dt.Temperature > 20]
dt = dt[dt.Temperature < 37]
dt.Temperature.hist()
plt.title('Temp')
plt.show()

dt.Humidity.hist()
plt.title('Humidity')
plt.show()


# In[10]:


############## Filtering - Moving average filter#################

y1 = dt['Jindal']
y2 = dt['NO2']
y3 = dt['SO2']
y4 = dt['CO']
y5 = dt['O3']
y6 = dt['Humidity']
y7 = dt['Temperature']

def smooth(y, box_pts):
    box = np.ones(box_pts)/box_pts
    y_smooth = np.convolve(y, box, mode='same')
    return y_smooth

z1 = smooth(y1,50)
z2 = smooth(y2,50)
z3 = smooth(y3,50)
z4 = smooth(y4,50)
z5 = smooth(y5,50)
z6 = smooth(y6,50)
z7 = smooth(y7,50)

dt['J'] = z1
dt['no2'] = z2
dt['so2'] = z3
dt['co'] = z4
dt['o3'] = z5
dt['H'] = z6
dt['tmp'] = z7

dt['Jindal'].plot(c='r')
dt['J'].plot(c='b')
plt.title('Jindal')
plt.show()

dt['NO2'].plot(c='r')
dt['no2'].plot(c='b')
plt.title('NO2')
plt.show()

dt['SO2'].plot(c='r')
dt['so2'].plot(c='b')
plt.title('SO2')
plt.show()

dt['CO'].plot(c='r')
dt['co'].plot(c='b')
plt.title('CO')
plt.show()

dt['O3'].plot(c='r')
dt['o3'].plot(c='b')
plt.title('O3')
plt.show()

dt['Humidity'].plot(c='r')
dt['H'].plot(c='b')
plt.title('Humidity')
plt.show()


dt['Temperature'].plot(c='r')
dt['tmp'].plot(c='b')
plt.title('Temp')
plt.show()


# In[14]:


# From the above graphs it observed that 
# initial and final values are low, remove them

dt = dt[dt.J > 3]
dt.J.hist()
plt.show()

dt = dt[dt.H > 43]
dt.H.hist()
plt.show()

dt = dt[dt.tmp > 26.5]
dt.tmp.hist()
plt.show()


# In[15]:


################# Standardizing data#############

from sklearn.preprocessing import StandardScaler

dt[['no2', 'so2', 'co', 'o3', 'H', 'tmp', 'J']] = StandardScaler().fit_transform(dt[['no2', 'so2', 'co', 'o3', 'H', 'tmp', 'J']])
dt


# In[26]:


################### Correlation matrix ###############

dt1 = dt[['no2', 'so2', 'co', 'o3']]
dt1.corr()


# In[53]:


####################### NO2 Estimators ######################

# Observation - NO2 has high correlation with CO and O3
# NO2 Estimators : NO2, CO, O3, Humidity, Temperature

from sklearn.model_selection import train_test_split

X = np.array(dt[['no2','co','o3','H','tmp']])
y = np.array(dt['J'])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=False)


# In[54]:


from keras.layers import Dense
from keras import optimizers
from keras.models import Sequential
from keras.callbacks import EarlyStopping
import tensorflow as tf

model = Sequential()
model.add(Dense(20, input_dim=5, activation=tf.sin, kernel_initializer='random_uniform', bias_initializer='zeros'))
model.add(Dense(20, activation='tanh', kernel_initializer='random_uniform', bias_initializer='zeros'))
model.add(Dense(20, activation='relu', kernel_initializer='random_uniform', bias_initializer='zeros'))
model.add(Dense(20, activation=tf.sin, kernel_initializer='random_uniform', bias_initializer='zeros'))
model.add(Dense(20, activation='tanh', kernel_initializer='random_uniform', bias_initializer='zeros'))
model.add(Dense(20, activation='relu', kernel_initializer='random_uniform', bias_initializer='zeros'))
model.add(Dense(20, activation=tf.sin, kernel_initializer='random_uniform', bias_initializer='zeros'))
model.add(Dense(1))
model.compile(loss='logcosh', optimizer='adam')
monitor = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=100, mode='auto', verbose=1)
history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=10, callbacks=[monitor], verbose=2, shuffle=True)

ypred = model.predict(X)


# In[57]:


dt['ypred'] = ypred

y_test_pred = model.predict(X_test)
y_train_pred = model.predict(X_train)

from sklearn.metrics import r2_score
print('Total_data :',r2_score(dt['J'], dt['ypred']))
print('test_data  :',r2_score(y_test, y_test_pred))
print('train_data :',r2_score(y_train, y_train_pred))

dt.J.plot(c='r')
dt.ypred.plot(c='b')
plt.show()

